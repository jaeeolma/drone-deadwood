{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp processing.postproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing\n",
    "\n",
    "> Smoothing, combining etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from drone_detector.imports import *\n",
    "from drone_detector.utils import *\n",
    "\n",
    "from skimage.morphology import erosion, dilation\n",
    "from scipy.ndimage.morphology import binary_fill_holes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-maximum suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the commonly used NMS with bounding boxes, that prioritizes either confidence score (default) or bounding box area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    " \n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, scores, overlap_thresh:float, sort_criterion:str='score'):\n",
    "    \"Possibility to sort boxes by score (default) or area\"\n",
    "    \n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    " \n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    " \n",
    "    # sort prediction by scores, \n",
    "\n",
    "    # initialize the list of picked indexes    \n",
    "    pick = []\n",
    " \n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    " \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    if sort_criterion == 'score':\n",
    "        idxs = np.argsort(scores)\n",
    "    elif sort_criterion == 'area':\n",
    "        idxs = np.argsort(area)\n",
    "    else:\n",
    "        print('Unknown sort criteria, reverting to \"score\"')\n",
    "        idxs = np.argsort(scores)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    " \n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    " \n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    " \n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    " \n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                         np.where(overlap > overlap_thresh)[0])))\n",
    " \n",
    "    # return indices for selected bounding boxes\n",
    "    return pick\n",
    "    #return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-max suppression can in theory be applied also on polygons, but it hasn't been used in any publications as far as I know.\n",
    "\n",
    "If `non_max_suppression_poly` is used to eliminate polygons, threshold might need to be smaller than typical value of 0.7 that is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from drone_detector.metrics import poly_IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def non_max_suppression_poly(geoms, scores, overlap_thresh:float, sort_criterion:str='score'):\n",
    "    \"Possibility to sort geoms by score (default) or area\"\n",
    "    \n",
    "    # if there are no geoms, return an empty list\n",
    "    if len(geoms) == 0:\n",
    "        return []\n",
    " \n",
    " \n",
    "    # sort prediction by scores, \n",
    "\n",
    "    # initialize the list of picked indexes    \n",
    "    pick = []\n",
    " \n",
    "    # compute the area of the bounding geoms and sort the bounding\n",
    "    # geoms by the bottom-right y-coordinate of the bounding box\n",
    "    area = np.array([geom.area for geom in geoms])\n",
    "    if sort_criterion == 'score':\n",
    "        idxs = np.argsort(scores)\n",
    "    elif sort_criterion == 'area':\n",
    "        idxs = np.argsort(area)\n",
    "    else:\n",
    "        print('Unknown sort criteria, reverting to \"score\"')\n",
    "        idxs = np.argsort(scores)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    " \n",
    "        # compute the ratio of overlap with all other polygons\n",
    "        overlap = np.array([poly_IoU(geoms[i], geoms[k]) for k in idxs[:last]])\n",
    "        # delete all indexes from the index list that have\n",
    "        # overlap larger than overlap_thresh\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                         np.where(overlap > overlap_thresh)[0])))\n",
    "         \n",
    "    # return indices for selected bounding geoms\n",
    "    return pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utils to run above functions to `GeoDataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def do_nms(gdf:gpd.GeoDataFrame, nms_thresh=0.7, crit='score'):\n",
    "    gdf = gdf.copy()\n",
    "    np_bboxes = np.array([b.bounds for b in gdf.geometry])\n",
    "    scores = gdf.score.values\n",
    "    idxs = non_max_suppression_fast(np_bboxes, scores, nms_thresh, crit)\n",
    "    gdf = gdf.iloc[idxs]\n",
    "    return gdf\n",
    "\n",
    "def do_poly_nms(gdf:gpd.GeoDataFrame, nms_thresh=0.1, crit='score'):\n",
    "    gdf = gdf.copy()\n",
    "    scores = gdf.score.values\n",
    "    idxs = non_max_suppression_poly(gdf.geometry.values, scores, nms_thresh, crit)\n",
    "    gdf = gdf.iloc[idxs]\n",
    "    return gdf\n",
    "\n",
    "def do_min_rot_rectangle_nms(gdf:gpd.GeoDataFrame, nms_thresh=0.7, crit='score'):\n",
    "    gdf = gdf.copy()\n",
    "    scores = gdf.score.values\n",
    "    boxes = np.array([g.minimum_rotated_rectangle for g in gdf.geometry.values])\n",
    "    idxs = non_max_suppression_poly(boxes, scores, nms_thresh, crit)\n",
    "    gdf = gdf.iloc[idxs]\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted boxes fusion\n",
    "\n",
    "Originally presented by [Solovyev et al (2021)](https://arxiv.org/abs/1910.13302), and available in [https://github.com/ZFTurbo/Weighted-Boxes-Fusion]. Code presented here is modified to keep track of original bounding boxes for mask fusion, and due to numpy version requirements we do not use numba here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As WBF expects normalized coordinates, first some helpers to normalize and denormalize geocoordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def normalize_bbox_coords(tot_bounds, bboxes):\n",
    "    xmin = tot_bounds[0]\n",
    "    ymin = tot_bounds[1]\n",
    "    width = tot_bounds[2] - tot_bounds[0]\n",
    "    height = tot_bounds[3] - tot_bounds[1]\n",
    "    \n",
    "    norm_bboxes = [((b[0]-xmin)/(width), \n",
    "                    (b[1]-ymin)/(height),\n",
    "                    (b[2]-xmin)/(width),\n",
    "                    (b[3]-ymin)/(height))\n",
    "                  for b in bboxes]\n",
    "    return norm_bboxes\n",
    "\n",
    "\n",
    "def denormalize_bbox_coords(tot_bounds, bboxes):\n",
    "    xmin = tot_bounds[0]\n",
    "    ymin = tot_bounds[1]\n",
    "    width = tot_bounds[2] - tot_bounds[0]\n",
    "    height = tot_bounds[3] - tot_bounds[1]\n",
    "    \n",
    "    norm_bboxes = [((b[0]*width+xmin), \n",
    "                    (b[1]*height+ymin),\n",
    "                    (b[2]*width+xmin),\n",
    "                    (b[3]*height+ymin))\n",
    "                  for b in bboxes]\n",
    "    return norm_bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def bb_intersection_over_union(A, B) -> float:\n",
    "    xA = max(A[0], B[0])\n",
    "    yA = max(A[1], B[1])\n",
    "    xB = min(A[2], B[2])\n",
    "    yB = min(A[3], B[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\n",
    "    if interArea == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth rectangles\n",
    "    boxAArea = (A[2] - A[0]) * (A[3] - A[1])\n",
    "    boxBArea = (B[2] - B[0]) * (B[3] - B[1])\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def prefilter_boxes(boxes, scores, labels, weights, thr):\n",
    "    # Create dict with boxes stored by its label\n",
    "    new_boxes = dict()\n",
    "\n",
    "    for t in range(len(boxes)):\n",
    "\n",
    "        if len(boxes[t]) != len(scores[t]):\n",
    "            print('Error. Length of boxes arrays not equal to length of scores array: {} != {}'.format(len(boxes[t]), len(scores[t])))\n",
    "            sys.exit()\n",
    "\n",
    "        if len(boxes[t]) != len(labels[t]):\n",
    "            print('Error. Length of boxes arrays not equal to length of labels array: {} != {}'.format(len(boxes[t]), len(labels[t])))\n",
    "            sys.exit()\n",
    "\n",
    "        for j in range(len(boxes[t])):\n",
    "            score = scores[t][j]\n",
    "            if score < thr:\n",
    "                continue\n",
    "            label = int(labels[t][j])\n",
    "            box_part = boxes[t][j]\n",
    "            x1 = max(float(box_part[0]), 0.)\n",
    "            y1 = max(float(box_part[1]), 0.)\n",
    "            x2 = max(float(box_part[2]), 0.)\n",
    "            y2 = max(float(box_part[3]), 0.)\n",
    "\n",
    "            # Box data checks\n",
    "            if x2 < x1:\n",
    "                warnings.warn('X2 < X1 value in box. Swap them.')\n",
    "                x1, x2 = x2, x1\n",
    "            if y2 < y1:\n",
    "                warnings.warn('Y2 < Y1 value in box. Swap them.')\n",
    "                y1, y2 = y2, y1\n",
    "            if x1 > 1:\n",
    "                warnings.warn('X1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
    "                x1 = 1\n",
    "            if x2 > 1:\n",
    "                warnings.warn('X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
    "                x2 = 1\n",
    "            if y1 > 1:\n",
    "                warnings.warn('Y1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
    "                y1 = 1\n",
    "            if y2 > 1:\n",
    "                warnings.warn('Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
    "                y2 = 1\n",
    "            if (x2 - x1) * (y2 - y1) == 0.0:\n",
    "                warnings.warn(\"Zero area box skipped: {}.\".format(box_part))\n",
    "                continue\n",
    "\n",
    "            # [label, score, weight, model index, x1, y1, x2, y2]\n",
    "            b = [int(label), float(score) * weights[t], weights[t], t, x1, y1, x2, y2]\n",
    "            if label not in new_boxes:\n",
    "                new_boxes[label] = []\n",
    "            new_boxes[label].append(b)\n",
    "\n",
    "    # Sort each list in dict by score and transform it to numpy array\n",
    "    for k in new_boxes:\n",
    "        current_boxes = np.array(new_boxes[k])\n",
    "        new_boxes[k] = current_boxes[current_boxes[:, 1].argsort()[::-1]]\n",
    "\n",
    "    return new_boxes\n",
    "\n",
    "\n",
    "def get_weighted_box(boxes, conf_type='avg'):\n",
    "    \"\"\"\n",
    "    Create weighted box for set of boxes\n",
    "    :param boxes: set of boxes to fuse\n",
    "    :param conf_type: type of confidence one of 'avg' or 'max'\n",
    "    :return: weighted box (label, score, weight, x1, y1, x2, y2)\n",
    "    \"\"\"\n",
    "\n",
    "    box = np.zeros(8, dtype=np.float32)\n",
    "    conf = 0\n",
    "    conf_list = []\n",
    "    w = 0\n",
    "    for b in boxes:\n",
    "        box[4:] += (b[1] * b[4:])\n",
    "        conf += b[1]\n",
    "        conf_list.append(b[1])\n",
    "        w += b[2]\n",
    "    box[0] = boxes[0][0]\n",
    "    if conf_type == 'avg':\n",
    "        box[1] = conf / len(boxes)\n",
    "    elif conf_type == 'max':\n",
    "        box[1] = np.array(conf_list).max()\n",
    "    elif conf_type in ['box_and_model_avg', 'absent_model_aware_avg']:\n",
    "        box[1] = conf / len(boxes)\n",
    "    box[2] = w\n",
    "    box[3] = -1 # model index field is retained for consistensy but is not used.\n",
    "    box[4:] /= conf\n",
    "    return box\n",
    "\n",
    "\n",
    "def find_matching_box_quickly(boxes_list, new_box, match_iou):\n",
    "    \"\"\" Reimplementation of find_matching_box with numpy instead of loops. Gives significant speed up for larger arrays\n",
    "        (~100x). This was previously the bottleneck since the function is called for every entry in the array.\n",
    "    \"\"\"\n",
    "    def bb_iou_array(boxes, new_box):\n",
    "        # bb interesection over union\n",
    "        xA = np.maximum(boxes[:, 0], new_box[0])\n",
    "        yA = np.maximum(boxes[:, 1], new_box[1])\n",
    "        xB = np.minimum(boxes[:, 2], new_box[2])\n",
    "        yB = np.minimum(boxes[:, 3], new_box[3])\n",
    "\n",
    "        interArea = np.maximum(xB - xA, 0) * np.maximum(yB - yA, 0)\n",
    "\n",
    "        # compute the area of both the prediction and ground-truth rectangles\n",
    "        boxAArea = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "        boxBArea = (new_box[2] - new_box[0]) * (new_box[3] - new_box[1])\n",
    "\n",
    "        iou = interArea / (boxAArea + boxBArea - interArea)\n",
    "\n",
    "        return iou\n",
    "\n",
    "    if boxes_list.shape[0] == 0:\n",
    "        return -1, match_iou\n",
    "\n",
    "    # boxes = np.array(boxes_list)\n",
    "    boxes = boxes_list\n",
    "\n",
    "    ious = bb_iou_array(boxes[:, 4:], new_box[4:])\n",
    "\n",
    "    ious[boxes[:, 0] != new_box[0]] = -1\n",
    "\n",
    "    best_idx = np.argmax(ious)\n",
    "    best_iou = ious[best_idx]\n",
    "\n",
    "    if best_iou <= match_iou:\n",
    "        best_iou = match_iou\n",
    "        best_idx = -1\n",
    "\n",
    "    return best_idx, best_iou\n",
    "\n",
    "\n",
    "def weighted_boxes_fusion(boxes_list, scores_list, labels_list, weights=None, iou_thr=0.55, skip_box_thr=0.0, conf_type='avg', allows_overflow=False):\n",
    "    '''\n",
    "    :param boxes_list: list of boxes predictions from each model, each box is 4 numbers.\n",
    "    It has 3 dimensions (models_number, model_preds, 4)\n",
    "    Order of boxes: x1, y1, x2, y2. We expect float normalized coordinates [0; 1]\n",
    "    :param scores_list: list of scores for each model\n",
    "    :param labels_list: list of labels for each model\n",
    "    :param weights: list of weights for each model. Default: None, which means weight == 1 for each model\n",
    "    :param iou_thr: IoU value for boxes to be a match\n",
    "    :param skip_box_thr: exclude boxes with score lower than this variable\n",
    "    :param conf_type: how to calculate confidence in weighted boxes. 'avg': average value, 'max': maximum value, 'box_and_model_avg': box and model wise hybrid weighted average, 'absent_model_aware_avg': weighted average that takes into account the absent model.\n",
    "    :param allows_overflow: false if we want confidence score not exceed 1.0\n",
    "    :return: boxes: boxes coordinates (Order of boxes: x1, y1, x2, y2).\n",
    "    :return: scores: confidence scores\n",
    "    :return: labels: boxes labels\n",
    "    :return: originals: original boxes\n",
    "    '''\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(boxes_list))\n",
    "    if len(weights) != len(boxes_list):\n",
    "        print('Warning: incorrect number of weights {}. Must be: {}. Set weights equal to 1.'.format(len(weights), len(boxes_list)))\n",
    "        weights = np.ones(len(boxes_list))\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    if conf_type not in ['avg', 'max', 'box_and_model_avg', 'absent_model_aware_avg']:\n",
    "        print('Unknown conf_type: {}. Must be \"avg\", \"max\" or \"box_and_model_avg\", or \"absent_model_aware_avg\"'.format(conf_type))\n",
    "        exit()\n",
    "\n",
    "    filtered_boxes = prefilter_boxes(boxes_list, scores_list, labels_list, weights, skip_box_thr)\n",
    "    if len(filtered_boxes) == 0:\n",
    "        return np.zeros((0, 4)), np.zeros((0,)), np.zeros((0,))\n",
    "\n",
    "    overall_boxes = []\n",
    "    original_boxes = []\n",
    "    for label in filtered_boxes:\n",
    "        boxes = filtered_boxes[label]\n",
    "        new_boxes = []\n",
    "        weighted_boxes = np.empty((0,8))\n",
    "        # Clusterize boxes\n",
    "        for j in range(0, len(boxes)):\n",
    "            index, best_iou = find_matching_box_quickly(weighted_boxes, boxes[j], iou_thr)\n",
    "\n",
    "            if index != -1:\n",
    "                new_boxes[index].append(boxes[j])\n",
    "                weighted_boxes[index] = get_weighted_box(new_boxes[index], conf_type)\n",
    "            else:\n",
    "                new_boxes.append([boxes[j].copy()])\n",
    "                weighted_boxes = np.vstack((weighted_boxes, boxes[j].copy()))\n",
    "        original_boxes.append(new_boxes)\n",
    "        # Rescale confidence based on number of models and boxes\n",
    "        for i in range(len(new_boxes)):\n",
    "            clustered_boxes = np.array(new_boxes[i])\n",
    "            if conf_type == 'box_and_model_avg':\n",
    "                # weighted average for boxes\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] * len(clustered_boxes) / weighted_boxes[i, 2]\n",
    "                # identify unique model index by model index column\n",
    "                _, idx = np.unique(clustered_boxes[:, 3], return_index=True)\n",
    "                # rescale by unique model weights\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] *  clustered_boxes[idx, 2].sum() / weights.sum()\n",
    "            elif conf_type == 'absent_model_aware_avg':\n",
    "                # get unique model index in the cluster\n",
    "                models = np.unique(clustered_boxes[:, 3]).astype(int)\n",
    "                # create a mask to get unused model weights\n",
    "                mask = np.ones(len(weights), dtype=bool)\n",
    "                mask[models] = False\n",
    "                # absent model aware weighted average\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] * len(clustered_boxes) / (weighted_boxes[i, 2] + weights[mask].sum())\n",
    "            elif conf_type == 'max':\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] / weights.max()\n",
    "            elif not allows_overflow:\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] * min(len(weights), len(clustered_boxes)) / weights.sum()\n",
    "            else:\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] * len(clustered_boxes) / weights.sum()\n",
    "        overall_boxes.append(weighted_boxes)\n",
    "    original_boxes = [item for sublist in original_boxes for item in sublist]\n",
    "    overall_boxes = np.concatenate(overall_boxes, axis=0)\n",
    "    sidx = overall_boxes[:, 1].argsort()\n",
    "    overall_boxes = overall_boxes[sidx[::-1]]\n",
    "    boxes = overall_boxes[:, 4:]\n",
    "    scores = overall_boxes[:, 1]\n",
    "    labels = overall_boxes[:, 0]\n",
    "    # sort originals accoring to wbf\n",
    "    #original_boxes = original_boxes[0]\n",
    "    wbfo = [original_boxes[i] for i in sidx[::-1]]\n",
    "    return boxes, scores, labels, wbfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def do_wbf(gdf:gpd.GeoDataFrame, iou_thr=0.55, skip_box_thr=0.5):\n",
    "    \"\"\"Run weighted_boxes_fusion and returns a gpd.GeoDataFrame where geometries are replaced by new bounding boxes.\n",
    "    Do not use with instance segmentation data unless you want to replace your results with bounding boxes\n",
    "    \"\"\"\n",
    "    np_bboxes = [b.bounds for b in gdf.geometry]\n",
    "    np_bboxes = normalize_bbox_coords(gdf.total_bounds, np_bboxes)\n",
    "    np_bboxes = [[b for b in np_bboxes]]\n",
    "    scores = [[v for v in gdf.score.values]]\n",
    "    labels = [[l for l in gdf.label.values]]\n",
    "    wbf_boxes, wbf_scores, wbf_labels, _ = weighted_boxes_fusion(np_bboxes, scores, labels, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    wbf_gdf = gpd.GeoDataFrame()\n",
    "    wbf_gdf['label'] = wbf_labels\n",
    "    wbf_gdf['score'] = wbf_scores\n",
    "    wbf_boxes = denormalize_bbox_coords(gdf.total_bounds, wbf_boxes)\n",
    "    wbf_gdf['geometry'] = [box(*bbox) for bbox in wbf_boxes]\n",
    "    wbf_gdf.crs = gdf.crs\n",
    "    return wbf_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def do_wsf(gdf:gpd.GeoDataFrame, iou_thr=0.55, skip_box_thr=0.5):\n",
    "    np_bboxes = [b.bounds for b in gdf.geometry]\n",
    "    np_bboxes = normalize_bbox_coords(gdf.total_bounds, np_bboxes)\n",
    "    np_bboxes = [[b for b in np_bboxes]]\n",
    "    scores = [[v for v in gdf.score.values]]\n",
    "    labels = [[l for l in gdf.label.values]]\n",
    "    wbf_boxes, wbf_scores, wbf_labels, originals = weighted_boxes_fusion(np_bboxes, scores, labels, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    wbf_gdf = gpd.GeoDataFrame()\n",
    "    wbf_gdf['label'] = wbf_labels\n",
    "    wbf_gdf['score'] = wbf_scores\n",
    "    wbf_boxes = denormalize_bbox_coords(gdf.total_bounds, wbf_boxes)\n",
    "    wbf_gdf['geometry'] = [box(*bbox) for bbox in wbf_boxes]\n",
    "    wbf_gdf.crs = gdf.crs\n",
    "    \n",
    "    wbf_scores = []\n",
    "    wbf_labels = []\n",
    "    wbf_masks = []\n",
    "    \n",
    "    for i, wbox in tqdm(enumerate(wbf_gdf.itertuples())):\n",
    "        wbf_scores.append(wbox.score)\n",
    "        wbf_labels.append(wbox.label)\n",
    "        orig_bboxes = [bbox[4:] for bbox in originals[i]]\n",
    "        orig_bboxes = denormalize_bbox_coords(gdf.total_bounds, orig_bboxes)\n",
    "        orig_bboxes = [box(*bounds) for bounds in orig_bboxes]\n",
    "        orig_masks = [m for m in gdf.geometry if box(*m.bounds) in orig_bboxes]\n",
    "        mask = shapely.ops.unary_union(orig_masks)\n",
    "        mask = mask.intersection(wbox.geometry)\n",
    "        wbf_masks.append(mask)\n",
    "    \n",
    "    mask_gdf = gpd.GeoDataFrame()\n",
    "    mask_gdf['label'] = wbf_labels\n",
    "    mask_gdf['score'] = wbf_scores\n",
    "    mask_gdf['geometry'] = wbf_masks\n",
    "    mask_gdf.crs = gdf.crs\n",
    "    \n",
    "    return mask_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing and filling holes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below functions are run before converting IceVision preds to COCO or shapefile format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def fill_holes(preds:list) -> list:\n",
    "    \"Run `binary_fill_holes` to predicted binary masks\"\n",
    "    for i, p in tqdm(enumerate(preds)):\n",
    "        for j in rangeof(p.pred.detection.label_ids):\n",
    "            p_mask = p.pred.detection.mask_array.to_mask(p.height, p.width).data[j]\n",
    "            p.pred.detection.mask_array.data[j] = binary_fill_holes(p_mask).astype(np.int8)\n",
    "    return preds\n",
    "    \n",
    "def dilate_erode(preds:list) -> list:\n",
    "    \"Run dilation followed by erosion in order to smooth masks\"\n",
    "    for i, p in tqdm(enumerate(preds)):\n",
    "        for j in rangeof(p.pred.detection.label_ids):\n",
    "            p_mask = p.pred.detection.mask_array.to_mask(p.height, p.width).data[j]\n",
    "            p.pred.detection.mask_array.data[j] = erosion(dilation(p_mask))\n",
    "    return preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
