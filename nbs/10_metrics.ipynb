{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom losses and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from drone_detector.imports import *\n",
    "from fastai.learner import Metric\n",
    "from fastai.torch_core import *\n",
    "from fastai.metrics import *\n",
    "from fastai.losses import BaseLoss\n",
    "import sklearn.metrics as skm\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "mk_class('ActivationType', **{o:o.lower() for o in ['No', 'Sigmoid', 'Softmax', 'BinarySoftmax']},\n",
    "         doc=\"All possible activation classes for `AccumMetric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def adjusted_R2Score(r2_score, n, k):\n",
    "    \"Calculates adjusted_R2Score based on r2_score, number of observations (n) and number of predictor variables(k)\"\n",
    "    return 1 - (((n-1)/(n-k-1)) * (1 - r2_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _rrmse(inp, targ):\n",
    "    \"RMSE normalized with mean of the target\"\n",
    "    return torch.sqrt(F.mse_loss(inp, targ)) / targ.mean() * 100\n",
    "\n",
    "rrmse = AccumMetric(_rrmse)\n",
    "rrmse.__doc__ = \"Target mean weighted rmse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bias(inp, targ):\n",
    "    \"Average bias of predictions\"\n",
    "    inp, targ = flatten_check(inp, targ)\n",
    "    return (inp - targ).sum() / len(targ)\n",
    "\n",
    "bias = AccumMetric(_bias)\n",
    "bias.__doc__ = \"Average bias of predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bias_pct(inp, targ):\n",
    "    \"Mean weighted bias\"\n",
    "    inp, targ = flatten_check(inp, targ)\n",
    "    return 100 * ((inp-targ).sum()/len(targ)) / targ.mean()\n",
    "\n",
    "bias_pct = AccumMetric(_bias_pct)\n",
    "bias_pct.__doc__ = 'Mean weighted bias'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BigEarthNet metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def label_ranking_average_precision_score(sigmoid=True, sample_weight=None):\n",
    "    \"\"\"Label ranking average precision (LRAP) is the average over each ground truth label assigned to each sample, \n",
    "    of the ratio of true vs. total labels with lower score.\"\"\"\n",
    "    activation = ActivationType.Sigmoid if sigmoid else ActivationType.No\n",
    "    return skm_to_fastai(skm.label_ranking_average_precision_score, sample_weight=None, flatten=False, thresh=None, \n",
    "                         activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def label_ranking_loss(sigmoid=True, sample_weight=None):\n",
    "    \"\"\"Compute the average number of label pairs that are incorrectly ordered given y_score \n",
    "    weighted by the size of the label set and the number of labels not in the label set.\"\"\"\n",
    "    activation = ActivationType.Sigmoid if sigmoid else ActivationType.No\n",
    "    return skm_to_fastai(skm.label_ranking_loss, sample_weight=None, flatten=False, thresh=None, \n",
    "                         activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def _one_error(inp, targ):\n",
    "    max_ranks = inp.argmax(axis=1)\n",
    "    faults = 0\n",
    "    for i in range_of(max_ranks):\n",
    "        faults += targ[i,max_ranks[i]]\n",
    "    return 1 - torch.true_divide(faults, len(max_ranks))\n",
    "    \n",
    "one_error = AccumMetric(_one_error, flatten=False)\n",
    "one_error.__doc__ = \"Rate for which the top ranked label is not among ground truth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def coverage_error(sigmoid=True, sample_weight=None):\n",
    "    \"\"\"Compute how far we need to go through the ranked scores to cover all true labels. \n",
    "    The best value is equal to the average number of labels in y_true per sample.\"\"\"\n",
    "    \n",
    "    activation = ActivationType.Sigmoid if sigmoid else ActivationType.No\n",
    "    return skm_to_fastai(skm.coverage_error, sample_weight=None, flatten=False, thresh=None, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import Learner\n",
    "class TstLearner(Learner):\n",
    "    def __init__(self,dls=None,model=None,**kwargs): self.pred,self.xb,self.yb = None,None,None\n",
    "\n",
    "def compute_val(met, x1, x2):\n",
    "    met.reset()\n",
    "    vals = [0,6,15,20]\n",
    "    learn = TstLearner()\n",
    "    for i in range(3):\n",
    "        learn.pred,learn.yb = x1[vals[i]:vals[i+1]],(x2[vals[i]:vals[i+1]],)\n",
    "        met.accumulate(learn)\n",
    "    return met.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrap = label_ranking_average_precision_score()\n",
    "lrl = label_ranking_loss()\n",
    "cov = coverage_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9863,  0.5349,  0.1619,  1.5855,  1.4731, -1.7488, -0.7248,  1.4115,\n",
       "           0.2501,  0.0907],\n",
       "         [ 0.6307, -2.8401,  1.0606,  1.4899,  0.2854, -0.2732, -0.5758, -0.4963,\n",
       "          -2.2258,  1.9919],\n",
       "         [ 0.2674, -0.0408,  0.1790, -1.1830, -0.1299, -1.3078,  0.4488,  0.4553,\n",
       "           0.5611, -1.1726],\n",
       "         [ 1.3335, -0.2782,  0.8992, -0.5221,  0.6512, -0.2832,  0.7030,  0.3703,\n",
       "           0.2219,  1.1805],\n",
       "         [ 1.4847,  0.5350, -0.6607,  0.6501,  1.0741, -0.7880,  0.3460, -0.1751,\n",
       "           1.0657,  0.2154],\n",
       "         [-0.6447, -0.2532, -0.1455,  0.2927,  0.8283,  0.9487, -1.6784, -0.1991,\n",
       "           0.8065, -1.1441],\n",
       "         [-0.6307, -1.0541, -0.1082, -1.1037, -1.3668, -0.3828, -1.1724,  0.6949,\n",
       "           1.3225,  0.4474],\n",
       "         [-0.0389,  0.0222, -2.2714, -0.1187,  0.5216,  0.8554,  0.0150, -1.5269,\n",
       "          -1.1638,  0.3692],\n",
       "         [-0.0507, -1.6455,  0.2197, -0.0557, -0.6117, -1.7797, -0.6482, -0.7175,\n",
       "           2.2846,  0.2458],\n",
       "         [-1.3037, -1.0383, -2.0695, -1.2144,  0.5075, -0.0061, -0.8563,  0.0708,\n",
       "          -0.6111,  0.5115]]),\n",
       " tensor([[0.2716, 0.6306, 0.5404, 0.8300, 0.8135, 0.1482, 0.3263, 0.8040, 0.5622,\n",
       "          0.5227],\n",
       "         [0.6527, 0.0552, 0.7428, 0.8161, 0.5709, 0.4321, 0.3599, 0.3784, 0.0975,\n",
       "          0.8799],\n",
       "         [0.5665, 0.4898, 0.5446, 0.2345, 0.4676, 0.2129, 0.6104, 0.6119, 0.6367,\n",
       "          0.2364],\n",
       "         [0.7914, 0.4309, 0.7108, 0.3724, 0.6573, 0.4297, 0.6689, 0.5915, 0.5553,\n",
       "          0.7650],\n",
       "         [0.8153, 0.6307, 0.3406, 0.6570, 0.7454, 0.3126, 0.5857, 0.4563, 0.7438,\n",
       "          0.5536],\n",
       "         [0.3442, 0.4370, 0.4637, 0.5727, 0.6960, 0.7209, 0.1573, 0.4504, 0.6914,\n",
       "          0.2416],\n",
       "         [0.3474, 0.2584, 0.4730, 0.2490, 0.2031, 0.4054, 0.2364, 0.6671, 0.7896,\n",
       "          0.6100],\n",
       "         [0.4903, 0.5056, 0.0935, 0.4704, 0.6275, 0.7017, 0.5038, 0.1784, 0.2380,\n",
       "          0.5913],\n",
       "         [0.4873, 0.1617, 0.5547, 0.4861, 0.3517, 0.1443, 0.3434, 0.3279, 0.9076,\n",
       "          0.5612],\n",
       "         [0.2135, 0.2615, 0.1121, 0.2289, 0.6242, 0.4985, 0.2981, 0.5177, 0.3518,\n",
       "          0.6252]]),\n",
       " tensor([[0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 0, 1, 1, 0, 1],\n",
       "         [1, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 1, 0, 0, 0, 1, 0, 0, 1]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = torch.randn(10,10)\n",
    "x_2 = torch.randint(2,(10,10))\n",
    "x_1, torch.sigmoid(x_1), x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49940476190476196"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_val(lrl, x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5268088624338624"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_val(lrap, x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_val(cov, x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_error(x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
