{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO utilities\n",
    "\n",
    "> Make coco annotations from shapefiles and transform predictions to shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from drone_detector.imports import *\n",
    "from drone_detector.utils import *\n",
    "from drone_detector.coordinates import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from drone_detector.coordinates import *\n",
    "from drone_detector.utils import *\n",
    "\n",
    "import datetime\n",
    "from skimage import measure\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary masks to polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# From https://github.com/waspinator/pycococreator/blob/master/pycococreatortools/pycococreatortools.py\n",
    "\n",
    "def resize_binary_mask(array, new_size):\n",
    "    image = Image.fromarray(array.astype(np.uint8)*255)\n",
    "    image = image.resize(new_size)\n",
    "    return np.asarray(image).astype(np.bool_)\n",
    "\n",
    "def close_contour(contour):\n",
    "    if not np.array_equal(contour[0], contour[-1]):\n",
    "        contour = np.vstack((contour, contour[0]))\n",
    "    return contour\n",
    "\n",
    "def binary_mask_to_polygon(binary_mask, tolerance=0):\n",
    "    \"\"\"Converts a binary mask to COCO polygon representation\n",
    "    Args:\n",
    "        binary_mask: a 2D binary numpy array where '1's represent the object\n",
    "        tolerance: Maximum distance from original points of polygon to approximated\n",
    "            polygonal chain. If tolerance is 0, the original coordinate array is returned.\n",
    "    \"\"\"\n",
    "    polygons = []\n",
    "    # pad mask to close contours of shapes which start and end at an edge\n",
    "    padded_binary_mask = np.pad(binary_mask, pad_width=1, mode='constant', constant_values=0)\n",
    "    contours = measure.find_contours(padded_binary_mask, 0.5)\n",
    "    contours = np.subtract(contours, 1)\n",
    "    for contour in contours:\n",
    "        contour = close_contour(contour)\n",
    "        contour = measure.approximate_polygon(contour, tolerance)\n",
    "        if len(contour) < 3:\n",
    "            continue\n",
    "        contour = np.flip(contour, axis=1)\n",
    "        segmentation = contour.ravel().tolist()\n",
    "        # after padding and subtracting 1 we may get -0.5 points in our segmentation \n",
    "        segmentation = [0 if i < 0 else i for i in segmentation]\n",
    "        polygons.append(segmentation)\n",
    "\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCOProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class COCOProcessor():\n",
    "    \"Handles Transformations from shapefiles to COCO-format and backwards\"\n",
    "    \n",
    "    def __init__(self, data_path:str, outpath:str, coco_info:dict, coco_licenses:list,\n",
    "                 coco_categories:list):\n",
    "        store_attr()\n",
    "        self.raster_path = f'{self.data_path}/raster_tiles'\n",
    "        self.vector_path = f'{self.data_path}/vector_tiles'\n",
    "        self.prediction_path = f'{self.data_path}/predicted_vectors'\n",
    "        \n",
    "        self.coco_dict = {\n",
    "            'info': coco_info,\n",
    "            'licenses': coco_licenses,\n",
    "            'images': [],\n",
    "            'annotations': [],\n",
    "            'categories': coco_categories,\n",
    "            'segment_info': []\n",
    "        }\n",
    "        self.categories = {c['name']:c['id'] for c in self.coco_dict['categories']}\n",
    "        \n",
    "        \n",
    "    def shp_to_coco(self, outfile:str='coco.json'):\n",
    "        \"Process shapefiles from self.vector_path to coco-format and save to self.outpath/outfile\"\n",
    "        vector_tiles = [f for f in os.listdir(self.vector_path) if f.endswith('.shp')]\n",
    "        # If no annotations are in found in raster tile then there is no shapefile for that\n",
    "        raster_tiles = [f'{fname[:-4]}.tif' for fname in vector_tiles]\n",
    "        self.coco_dict['images'] = [{'file_name': raster_tiles[i],\n",
    "                                     'id': i} for i in rangeof(raster_tiles)]\n",
    "        ann_id = 0\n",
    "        for i in tqdm(rangeof(raster_tiles)):\n",
    "            gdf = gpd.read_file(f'{self.vector_path}/{vector_tiles[i]}')\n",
    "            tfmd_gdf = gdf_to_px(gdf, f'{self.raster_path}/{raster_tiles[i]}')\n",
    "            for row in tfmd_gdf.itertuples():\n",
    "                category_id = self.categories[row.label]\n",
    "                self.coco_dict['annotations'].append(_process_shp_to_coco(i, category_id, ann_id, row.geometry))\n",
    "                ann_id += 1\n",
    "        with open(f'{self.outpath}/{outfile}', 'w') as f: json.dump(self.coco_dict, f)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def coco_to_shp(self, coco_data:dict=None, outdir:str='predicted_vectors'):\n",
    "        \"\"\"Generates shapefiles from a dictionary with coco annotations.\n",
    "        TODO handle multipolygons better\"\"\"\n",
    "        \n",
    "        if not os.path.exists(f'{self.outpath}/{outdir}'): os.makedirs(f'{self.outpath}/{outdir}')\n",
    "        #if coco_path is None: coco_path = f'{self.outpath}/coco.json'\n",
    "        #with open(coco_path) as f:\n",
    "        #    coco_data = json.load(f)\n",
    "        \n",
    "        annotations = coco_data['annotations']\n",
    "        images = coco_data['images']\n",
    "        categories = coco_data['categories']\n",
    "        for i in tqdm(images):\n",
    "            anns_in_image = [a for a in annotations if a['image_id'] == i['id']]\n",
    "            if len(anns_in_image) == 0: continue\n",
    "            cats = []\n",
    "            polys = []\n",
    "            for a in anns_in_image:\n",
    "                # No segmentations, only bounding boxes\n",
    "                if a['segmentation'] is None:\n",
    "                    cats.append(a['category_id'])\n",
    "                    # Bbox has format xmin, ymin, xdelta, ydelta\n",
    "                    polys.append(box(a['bbox'][0], a['bbox'][1], a['bbox'][2] + a['bbox'][0], a['bbox'][3]+a['bbox'][1]))\n",
    "                \n",
    "                # Single polygon\n",
    "                elif len(a['segmentation']) == 1:\n",
    "                    cats.append(a['category_id'])\n",
    "                    xy_coords = [(a['segmentation'][0][i], a['segmentation'][0][i+1]) \n",
    "                                 for i in range(0,len(a['segmentation'][0]),2)]\n",
    "                    xy_coords.append(xy_coords[-1])\n",
    "                    polys.append(Polygon(xy_coords))\n",
    "                    \n",
    "                # Multipolygon \n",
    "                else: \n",
    "                    for p in rangeof(a['segmentation']):\n",
    "                        cats.append(a['category_id'])\n",
    "                        xy_coords = [(a['segmentation'][p][i], a['segmentation'][p][i+1]) \n",
    "                                     for i in range(0,len(a['segmentation'][p]),2)]\n",
    "                        xy_coords.append(xy_coords[-1])\n",
    "                        polys.append(Polygon(xy_coords))\n",
    "            gdf = gpd.GeoDataFrame({'label':cats, 'geometry':polys})\n",
    "            tfmd_gdf = georegister_px_df(gdf, f'{self.raster_path}/{i[\"file_name\"]}')\n",
    "            tfmd_gdf.to_file(f'{self.outpath}/{outdir}/{i[\"file_name\"][:-4]}.shp')\n",
    "        return\n",
    "\n",
    "def mask_preds_to_coco_anns(preds:list) -> dict:\n",
    "    \"\"\"Process list of IceVision `samples` and `preds` to COCO-annotation polygon format. \n",
    "    Returns a dict with Coco-style `images` and `annotations`\n",
    "    \n",
    "    TODO replace these with functions from icevision somehow\"\"\"\n",
    "    outdict = {}\n",
    "    outdict['annotations'] = []\n",
    "    outdict['images'] = [{'file_name': str(f'{p.ground_truth.filepath.stem}{p.ground_truth.filepath.suffix}'), 'id': p.record_id} for p in preds]\n",
    "    anns = []\n",
    "    for i, p in tqdm(enumerate(preds)): \n",
    "        for j in rangeof(p.detection.masks):\n",
    "            anns = []\n",
    "            ann_dict = {\n",
    "                'segmentation': binary_mask_to_polygon(p.detection.masks.to_mask(p.height,p.width).data[j]),\n",
    "                'area': None,  \n",
    "                'iscrowd': 0,\n",
    "                'category_id': p.detection.label_ids[j].item(),\n",
    "                'id': i,\n",
    "                'image_id': p.record_id,\n",
    "                'bbox': [p.detection.bboxes[j].xmin.item(), \n",
    "                         p.detection.bboxes[j].ymin.item(),\n",
    "                         p.detection.bboxes[j].xmax.item() - p.detection.bboxes[j].xmin.item(),\n",
    "                         p.detection.bboxes[j].ymax.item() - p.detection.bboxes[j].ymin.item()]\n",
    "            }\n",
    "\n",
    "\n",
    "            anns.append(ann_dict)\n",
    "            outdict['annotations'].extend(anns)\n",
    "\n",
    "    return outdict\n",
    "\n",
    "def bbox_preds_to_coco_anns(preds:list) -> dict:\n",
    "    \"\"\"Process list of IceVision `samples` and `preds` to COCO-annotation polygon format. \n",
    "    Returns a dict with Coco-style `images` and `annotations`\"\"\"\n",
    "    outdict = {}\n",
    "    outdict['annotations'] = []\n",
    "    outdict['images'] = [{'file_name': str(f'{p.ground_truth.filepath.stem}{p.ground_truth.filepath.suffix}'), 'id': p.record_id} for p in preds]\n",
    "\n",
    "    anns = []\n",
    "    for i, p in tqdm(enumerate(preds)): \n",
    "        for j in rangeof(p.detection.bboxes):\n",
    "            anns = []\n",
    "            ann_dict = {\n",
    "                'segmentation': None,\n",
    "                'area': None,  \n",
    "                'iscrowd': 0,\n",
    "                'category_id': p.detection.label_ids[j].item(),\n",
    "                'id': i,\n",
    "                'image_id': s.record_id,\n",
    "                'bbox': [p.detection.bboxes[j].xmin.item(), \n",
    "                         p.detection.bboxes[j].ymin.item(),\n",
    "                         p.detection.bboxes[j].xmax.item() - p.detection.bboxes[j].xmin.item(),\n",
    "                         p.detection.bboxes[j].ymax.item() - p.detection.bboxes[j].ymin.item()]\n",
    "            }\n",
    "\n",
    "            anns.append(ann_dict)\n",
    "            outdict['annotations'].extend(anns)\n",
    "\n",
    "    return outdict\n",
    "\n",
    "    \n",
    "def _process_shp_to_coco(image_id, category_id, ann_id, poly:Polygon):\n",
    "    \"TODO handle multipolygons\"\n",
    "    ann_dict = {\n",
    "        'segmentation': [],\n",
    "        'area': None, \n",
    "        'bbox': [],\n",
    "        'category_id': category_id,\n",
    "        'id' : ann_id,\n",
    "        'image_id': image_id,\n",
    "        'iscrowd': 0,\n",
    "    }\n",
    "    ann_dict['bbox'] = [(poly.bounds[0]), \n",
    "                        (poly.bounds[1]), \n",
    "                        (poly.bounds[2]-poly.bounds[0]), \n",
    "                        (poly.bounds[3]-poly.bounds[1])]\n",
    "    ann_dict['area'] = poly.area\n",
    "    if poly.type == 'Polygon':\n",
    "        ann_dict['segmentation'] = [list(sum(poly.exterior.coords[:-1], ()))]\n",
    "    elif poly.type == 'MultiPolygon':\n",
    "        ann_dict['segmentation'] = [list(sum(p.exterior.coords[:-1], ())) for p in list(poly)]\n",
    "    return ann_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
