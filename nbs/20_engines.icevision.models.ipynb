{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db43fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp engines.icevision.models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7bb241",
   "metadata": {},
   "source": [
    " # Models\n",
    " \n",
    " > Utilities to customize Mask R-CNN anchor sizes, and save icevision models with their configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from drone_detector.imports import *\n",
    "from drone_detector.utils import *\n",
    "from icevision.models.torchvision import *\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN, MaskRCNNPredictor\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def mask_rcnn_custom_anchors(num_classes:int,\n",
    "                             backbone=None,\n",
    "                             pretrained:bool=True,\n",
    "                             sizes:tuple=((32,), (64,), (128,), (256,), (512,)),\n",
    "                             aspect_ratios:tuple=(0.5, 1.0, 2.0),\n",
    "                             min_size:int=800,\n",
    "                             max_size:int=1333\n",
    "    \n",
    "    ) -> nn.Module:\n",
    "    \"Make icevision Mask RCNN with custom anchors. Default values are torchvision defaults\"\n",
    "    \n",
    "    \n",
    "    if backbone is None:\n",
    "        backbone = mask_rcnn.backbones.resnet50_fpn(pretrained=pretrained)\n",
    "    \n",
    "    rpn_anchor_generator = AnchorGenerator(sizes=sizes,\n",
    "                                           aspect_ratios=aspect_ratios)\n",
    "    \n",
    "    rpn_head = RPNHead(256, rpn_anchor_generator.num_anchors_per_location()[0])\n",
    "    \n",
    "    in_features = 1024\n",
    "    \n",
    "    box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    in_features_mask = 256\n",
    "    \n",
    "    hidden_layer = 256\n",
    "    mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    \n",
    "    mask_rcnn_kwargs = {\n",
    "        'rpn_anchor_generator': rpn_anchor_generator,\n",
    "        'rpn_head': rpn_head,\n",
    "        'box_predictor': box_predictor,\n",
    "        'mask_predictor': mask_predictor,\n",
    "        'num_classes': None,\n",
    "        'image_mean': [1., 1., 1.],\n",
    "        'image_std': [1., 1., 1.], # This way no need to remove model normalization\n",
    "        'min_size': min_size,\n",
    "        'max_size': max_size\n",
    "    }\n",
    "    \n",
    "    custom_model = mask_rcnn.model(backbone=backbone, remove_internal_transforms=False, **mask_rcnn_kwargs)\n",
    "    \n",
    "    return custom_model\n",
    "\n",
    "\n",
    "def faster_rcnn_custom_anchors(num_classes:int,\n",
    "                               backbone=None,\n",
    "                               pretrained:bool=True,\n",
    "                               sizes:tuple=((32,), (64,), (128,), (256,), (512,)),\n",
    "                               aspect_ratios:tuple=(0.5, 1.0, 2.0),\n",
    "                               min_size:int=800, # Default value\n",
    "                               max_size:int=1333 # Default value\n",
    "    \n",
    "    ) -> nn.Module:\n",
    "    \"Make icevision Faster RCNN with custom anchors. Default values are torchvision defaults\"\n",
    "    \n",
    "    \n",
    "    if backbone is None:\n",
    "        backbone = mask_rcnn.backbones.resnet50_fpn(pretrained=pretrained)\n",
    "    \n",
    "    rpn_anchor_generator = AnchorGenerator(sizes=sizes,\n",
    "                                           aspect_ratios=aspect_ratios)\n",
    "    \n",
    "    rpn_head = RPNHead(256, rpn_anchor_generator.num_anchors_per_location()[0])\n",
    "    \n",
    "    in_features = 1024\n",
    "    \n",
    "    box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    faster_rcnn_kwargs = {\n",
    "        'rpn_anchor_generator': rpn_anchor_generator,\n",
    "        'rpn_head': rpn_head,\n",
    "        'box_predictor': box_predictor,\n",
    "        'num_classes': None,\n",
    "        'image_mean': (1.,1.,1.),\n",
    "        'image_std': (1.,1.,1.), # This way no need to remove model normalization\n",
    "        'min_size': min_size,\n",
    "        'max_size': max_size\n",
    "    }\n",
    "    \n",
    "    custom_model = faster_rcnn.model(backbone=backbone, **faster_rcnn_kwargs, remove_internal_transforms=False)\n",
    "    \n",
    "    return custom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42c160d",
   "metadata": {},
   "source": [
    "In order to easily load custom model configurations, save the required information to a config json-file. The file has a format of\n",
    "\n",
    "* `model_type`: either `'mask_rcnn'` or `'faster_rcnn'`\n",
    "* `backbone_name`: name of the torchvision model used as backbone, e.g. `'resnext101_32x8d_fpn'`\n",
    "* `anchor_generator_sizes`: List of the anchor sizes, e.g. `[32,64,128,256,512]` is the default\n",
    "* `aspect_ratios`: List of the used aspect ratios for anchors, e.g. `[0.5, 1, 2]` is the default\n",
    "* `categories`: COCO-style dict of categories the model is trained on\n",
    "* `model_fname`: filename for the trained weights\n",
    "\n",
    "Both `model.pth` and `config.json` are saved in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd668ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def save_model_and_config(outdir, \n",
    "                          model,\n",
    "                          backbone_name, \n",
    "                          model_type, \n",
    "                          categories, \n",
    "                          min_size:int=800,\n",
    "                          max_size:int=1333):\n",
    "    if os.path.exists(outdir):\n",
    "        print('Output directory exists')\n",
    "        return\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "    anchor_generator_sizes = model.rpn.anchor_generator.sizes\n",
    "    aspect_ratios = model.rpn.anchor_generator.aspect_ratios[0]\n",
    "    backbone_name = backbone_name\n",
    "    model_path = f'{outdir}/model.pth'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    outdict = {\n",
    "        'model_type': model_type,\n",
    "        'backbone_name': backbone_name,\n",
    "        'anchor_generator_sizes': [s[0] for s in anchor_generator_sizes],\n",
    "        'aspect_ratios': list(aspect_ratios),\n",
    "        'categories': categories,\n",
    "        'min_size': min_size,\n",
    "        'max_size': max_size\n",
    "    }\n",
    "    \n",
    "    with open(f'{outdir}/config.json', 'w') as dest:\n",
    "        json.dump(outdict, dest)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def load_rcnn_from_config(path_to_conf):\n",
    "    \"Load model according to config\"\n",
    "    \n",
    "    with open(f'{path_to_conf}/config.json') as conf:\n",
    "        conf_dict = json.load(conf)\n",
    "        \n",
    "    backbone_name = conf_dict['backbone_name']\n",
    "    \n",
    "    anchor_generator_sizes = tuple([(s,) for s in conf_dict['anchor_generator_sizes']])\n",
    "    aspect_ratios = tuple(conf_dict['aspect_ratios'])\n",
    "    \n",
    "    num_classes = len(conf_dict['categories']) + 1\n",
    "    min_size = conf_dict['min_size']\n",
    "    max_size = conf_dict['max_size']\n",
    "    \n",
    "    \n",
    "    if conf_dict['model_type'] == 'faster_rcnn': \n",
    "        model_type = faster_rcnn\n",
    "        backbone = getattr(model_type.backbones, backbone_name)(pretrained=False)\n",
    "        print('Not yet implemented')\n",
    "        return\n",
    "        \n",
    "    elif conf_dict['model_type'] == 'mask_rcnn': \n",
    "        model_type = mask_rcnn\n",
    "        backbone = getattr(model_type.backbones, backbone_name)(pretrained=False)\n",
    "        custom_model = mask_rcnn_custom_anchors(num_classes=num_classes, \n",
    "                                                backbone=backbone, \n",
    "                                                sizes=anchor_generator_sizes,\n",
    "                                                aspect_ratios=aspect_ratios,\n",
    "                                                min_size=min_size,\n",
    "                                                max_size=max_size)\n",
    "    \n",
    "   \n",
    "    device = 'cpu' if not torch.cuda.is_available() else f'cuda:{torch.cuda.current_device()}'\n",
    "    state_dict = torch.load(f'{path_to_conf}/model.pth', map_location=device)\n",
    "    custom_model.load_state_dict(state_dict)\n",
    "    if device != 'cpu': custom_model.to(torch.device('cuda'))\n",
    "        \n",
    "    return custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de1939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
